## Замеры производительности сервисов

Запуск был осуществлен в docker под Mac OS X

### Сервис без кэширования

| Время / Потоки / Соединения | Latency  | RPS           |
| --------------------------- | -------- | ------------- |
| 60 / 1 / 1                  | 23.66ms  | 44.96         |
| 60 / 10 / 10                | 222.24ms | 44.94         |               
| 60 / 50 / 50                | 625.99ms | 0.2           |

Интересный результат при 50 поток и соединений. Там вообще большинство запросов остается висеть и не исполняется. Об этом ниже. 

Дополнительно попробовал убрать async на методе получения автора в сервисе.
Тогда данные в варианте 50 потоков - совсем другие. Но по крайней мере, сервис не зависает.

```
Latency = 1.3s, RPS = 32.61
```

Из документации по fastapi следует, что если нет async - то используется собственный тред-пул.
Скорее всего он более ограниченного размера и при большом количестве запросов просто вырастает очередь и время ожидания, но уменьшается overhead на многопоточность.

Также, эффективность async проявляется там, где внутренний код поддерживает асинхронность. Общение с базой в данной реализации сервиса - синхронное.

### Сервис с кэшированием

| Время / Потоки / Соединения | Latency  | RPS           |
| --------------------------- | -------- | ------------- |
| 60 / 1 / 1                  | 13.22ms  | 91.73         |
| 60 / 10 / 10                | 90.23ms  | 111.82        |               
| 60 / 50 / 50                | 654.29ms | 0.22          |

Здесь с асинхронностью чуть интереснее. Redis ее поддерживает, а база нет.
Убрать полностью async нельзя - из-за Redis (т.е. можно если использовать синхронный модуль доступа).

Начал разбираться, что случается с сервисом, почему он зависает.
Небольшой знаток питона, использовал его еще давно в версии 2 - когда никаких async не было.

Но насколько я понял - происходит взаимная блокировка на получении соединения (сессии) к базе.
Т.е. пул соединений исчерпывается (он по умолчанию больше 10, но меньше 50), потом зависает на ожидании получения соединения в генераторе get_db, но при этом, возможно, как то генератор блокирует освобождение других соединений.

Таким образом некоторые запросы в начале успевают выполнится, а далее происходит dead-lock.

Увеличил размер пула:

```
engine = create_engine("mysql+pymysql://"+DB_USER+":"+DB_PASSWORD+"@"+DB_HOST+":"+DB_PORT+"/"+DB_SCHEME, echo = True, pool_size = 50)
```

Это исправило проблему. Получились такие результаты:

| Время / Потоки / Соединения | Latency  | RPS           |
| --------------------------- | -------- | ------------- |
| 60 / 30 / 30                | 434.57ms | 69.59         |
| 60 / 40 / 40                | 605.80ms | 65.72         |               
| 60 / 50 / 50                | 815.82ms | 60.83         |

**Вывод**

* Увеличение количества потоков порождает дополнительный overhead на синхнронизацию, далеко не всегда сервис оказывается готов к масштабированию
* Требуется прикладывать дополнительные усилия в коде, чтобы в многопоточной среде он оставался эффективным
  